wno_data$id <- paste0(wno_data$org, wno_data$year)
wno_data <- dplyr::left_join(wno_data, hisp, by = "id")
wno_data$log_hisppop <- log(wno_data$hisp_new.y)
saveRDS(wno_data, "data/wno_data.rds")
source("scripts/perm_table.R")
doc_type <- readRDS("data/doc_type.rds") #Doc type for all 384 docs (for frequency table)
meta <- readRDS("data/meta.rds")
desc9708 <- read.csv("data/group_desc.csv", header = T) %>%
pivot_longer(cols = KKK:White.Nationalist) #for the intro figure
wno_data <- readRDS("data/wno_data.rds") #Main data, processed and ready to go
fig1 <- ggplot(data = desc9708, aes(x = Year, y = value, group = name, colour = name)) +
geom_line(size = 1) +
geom_point(size = 2) +
scale_x_continuous(breaks = seq(1997, 2008, 2)) +
theme_bw() +
theme(axis.title.y = element_text(size = 10, face = "bold"),
legend.position = "bottom",
legend.title=element_text(face = "bold")) +
xlab("") + ylab("Total Number of Organizations in U.S.") +
scale_colour_manual(name = "",breaks = c("KKK","Neo.Nazi","Racist.Skinhead","Identity","Neo.Confederate","White.Nationalist"),
labels = c("KKK","Neo-Nazi","Racist Skinhead","Christian Identity","Neo-Confederate",
"White Nationalist"),
values = c("#1696d2","#fdbf11","#ec008b",
"#55b748","#5c5859","#db2b27"))
ggsave("figures/fig1.jpeg", dpi = 300, height = 6, width = 8, units = "in")
fig1
dev.off()
fig2 <- meta %>%
group_by(state, org) %>%
dplyr::summarize(sum = 1) %>%
ungroup() %>%
group_by(state) %>%
dplyr::summarize(sum = n()) %>%
mutate(state = recode_factor(state, "Mississippii" = "Mississippi")) %>%
mutate(state = fct_reorder(state, desc(sum))) %>%
ggplot(aes(x = state, y = sum)) +
geom_col(color = "black", fill = "#1696d2") +
theme_bw() +
labs(x = "", y = "Total Number of Sampled Organizations") +
theme(axis.title.y = element_text(face = "bold")) +
scale_x_discrete(guide = guide_axis(n.dodge = 2))
ggsave("figures/fig2.jpeg", dpi = 300, height = 6, width = 12, units = "in")
fig2
dev.off()
freq_table(as.data.frame(doc_type), doc_type)
model <- plm(immigration ~ log_terror*log_hisppop + discursive_style +
per_repub + vcrime_rate + factor(reform) + p2001 + log_vocality +
word_count + factor(admin),
data = wno_data,
index = c("org","year"),
model = "within")
mat <- perm_tester(data = wno_data, model = model,
perm_var = "immigration", statistic = "coefficients",
strat_var = "org", seed = 123)
mat
wno_data[,c("org","year","log_hisppop")]
wno_data[,c("org","year","log_hisppop")] |> as.data.frame()
wno_data[,c("org","year","log_hisppop","hisp_new.y")] |> as.data.frame()
cor(wno_data$hisp_new.x,wno_data$hisp_new.y)
mat$var <- factor(mat$rowname, levels = rev(mat$rowname))
labels <- c("U.S. Terror Threats/Attacks (logged)","Hispanic Population (logged)",
"Discursive Style (logit-transformed)","% Republican Voting in County",
"Violent Crime Rate in County (logged)","Immigration Legislation",
"Post-2001 Publication","Writer Heterogeneity (logged)",
"(Mean) Word Count","Reagan Administration",
"H.W. Bush Administration","W. Bush Administration",
"Terror \u00D7 Hispanic")
coefs <- mat$stat %>% round(3)
coefs.lab <- list()
for (i in coefs) {
coefs.lab[[match(i, coefs)]] <- substitute(paste(hat(beta), " = ", i),
list(i = i))
}
fig3 <- mat %>%
ggplot(aes(x = var, y = P_two)) +
geom_col(color = "black", fill = "gray50") +
geom_errorbar(aes(ymin = CI_two_lo, ymax = CI_two_up), width = 0.1) +
geom_text(aes(label = coefs.lab), parse = T, hjust = -.75) +
geom_hline(yintercept = 0.05, linetype = "dashed") +
labs(x = "", y = expression(bold(paste("Two-Tailed ", italic("P"), "-Values")))) +
scale_x_discrete(labels = rev(labels)) +
theme_bw() +
theme(axis.title = element_text(face = "bold"),
axis.text.y = element_text(face = "bold"),
axis.text.x = element_text(size = 8),
panel.grid.minor.x = element_blank()) +
scale_y_continuous(expand = c(0.005,0),
limits = c(0,1.2),
breaks = c(0,.05,seq(.25, 1, by = .25)),
labels = c("0.00", expression(paste(italic("p"),
" = 0.05")),
"0.25", "0.50", "0.75", "1.00")) +
coord_flip()
ggsave("figures/fig3.jpeg", dpi = 600, height = 6, width = 12, units = "in")
fig3
dev.off()
nrow(model$model)
#Models 1 and 2 in Table 5 of the Appendix
#Model 1
model.1 <- plm(immigration ~ log_terror,
data = wno_data,
index = c("org","year"),
model = "within")
mat.1 <- perm_table(data = wno_data, model = model.1,
perm_v = "immigration", statistic = "coefficients",
strata_v = "org", seed = 123) #Need perm_table() instead of
mat.1
predictions(model, variables = list(log_terror = seq(quantile(wno_data$log_terror, .25, na.rm = T),
quantile(wno_data$log_terror, .75, na.rm = T),
by = .25),
log_hisppop2 = c(quantile(wno_data$log_hisppop2, .25, na.rm = T),
quantile(wno_data$log_hisppop2, .5, na.rm = T),
quantile(wno_data$log_hisppop2, .75, na.rm = T))),
newdata = model.data) %>%
rbind(.,
predictions(model2, variables = list(log_terror = seq(quantile(wno_data$log_terror, .25, na.rm = T),
quantile(wno_data$log_terror, .75, na.rm = T),
by = .25),
log_hisppop2 = c(quantile(wno_data$log_hisppop2, .25, na.rm = T),
quantile(wno_data$log_hisppop2, .5, na.rm = T),
quantile(wno_data$log_hisppop2, .75, na.rm = T))),
newdata = model.data2)) %>%
mutate(model_id = c(rep("model", 1296), rep("model2", (tally(.) - 1296))),
log_terror = (exp(log_terror)-1),
log_hisppop2 = exp(log_hisppop2)) %>%
select(rowid, predicted, log_hisppop2, log_terror, model_id) %>%
mutate(predicted = (exp(predicted)/(1 + exp(predicted)))) %>%
group_by(log_hisppop2, log_terror, model_id) %>%
summarise(predicted_sum = mean(predicted))
predictions(model, variables = list(log_terror = seq(quantile(wno_data$log_terror, .25, na.rm = T),
quantile(wno_data$log_terror, .75, na.rm = T),
by = .25),
log_hisppop = c(quantile(wno_data$log_hisppop, .25, na.rm = T),
quantile(wno_data$log_hisppop, .5, na.rm = T),
quantile(wno_data$log_hisppop, .75, na.rm = T))),
newdata = model.data) %>%
rbind(.,
predictions(model2, variables = list(log_terror = seq(quantile(wno_data$log_terror, .25, na.rm = T),
quantile(wno_data$log_terror, .75, na.rm = T),
by = .25),
log_hisppop = c(quantile(wno_data$log_hisppop, .25, na.rm = T),
quantile(wno_data$log_hisppop, .5, na.rm = T),
quantile(wno_data$log_hisppop, .75, na.rm = T))),
newdata = model.data2)) %>%
mutate(model_id = c(rep("model", 1296), rep("model2", (tally(.) - 1296))),
log_terror = (exp(log_terror)-1),
log_hisppop = exp(log_hisppop)) %>%
select(rowid, predicted, log_hisppop, log_terror, model_id) %>%
mutate(predicted = (exp(predicted)/(1 + exp(predicted)))) %>%
group_by(log_hisppop, log_terror, model_id) %>%
summarise(predicted_sum = mean(predicted))
wno_data2 <- wno_data[wno_data$year != 2002,] #Removing 2002 org-years
model2 <- plm(immigration ~ log_terror*log_hisppop + discursive_style +
per_repub + vcrime_rate + factor(reform) + p2001 + log_vocality +
word_count + factor(admin),
data = wno_data2,
index = c("org","year"),
model = "within") #the model with 2002 org-years removed
mat2 <- perm_tester(data = wno_data2, model = model2,
perm_var = "immigration", statistic = "coefficients",
strat_var = "org", seed = 123)
labs <- c("2002 Org-Years Included","2002 Org-Years Not Included")
names(labs) <- c("model","model2")
model.data <- as.data.frame(model$model)
model.data <- model.data %>%
rename(admin = `factor.admin.`,
reform = `factor.reform.`)
model.data2 <- as.data.frame(model2$model)
model.data2 <- model.data2 %>%
rename(admin = `factor.admin.`,
reform = `factor.reform.`)
predictions(model, variables = list(log_terror = seq(quantile(wno_data$log_terror, .25, na.rm = T),
quantile(wno_data$log_terror, .75, na.rm = T),
by = .25),
log_hisppop = c(quantile(wno_data$log_hisppop, .25, na.rm = T),
quantile(wno_data$log_hisppop, .5, na.rm = T),
quantile(wno_data$log_hisppop, .75, na.rm = T))),
newdata = model.data) %>%
rbind(.,
predictions(model2, variables = list(log_terror = seq(quantile(wno_data$log_terror, .25, na.rm = T),
quantile(wno_data$log_terror, .75, na.rm = T),
by = .25),
log_hisppop = c(quantile(wno_data$log_hisppop, .25, na.rm = T),
quantile(wno_data$log_hisppop, .5, na.rm = T),
quantile(wno_data$log_hisppop, .75, na.rm = T))),
newdata = model.data2)) %>%
mutate(model_id = c(rep("model", 1296), rep("model2", (tally(.) - 1296))),
log_terror = (exp(log_terror)-1),
log_hisppop = exp(log_hisppop)) %>%
select(rowid, predicted, log_hisppop, log_terror, model_id) %>%
mutate(predicted = (exp(predicted)/(1 + exp(predicted)))) %>%
group_by(log_hisppop, log_terror, model_id) %>%
summarise(predicted_sum = mean(predicted))
temp <- predictions(model, variables = list(log_terror = seq(quantile(wno_data$log_terror, .25, na.rm = T),
quantile(wno_data$log_terror, .75, na.rm = T),
by = .25),
log_hisppop = c(quantile(wno_data$log_hisppop, .25, na.rm = T),
quantile(wno_data$log_hisppop, .5, na.rm = T),
quantile(wno_data$log_hisppop, .75, na.rm = T))),
newdata = model.data) %>%
rbind(.,
predictions(model2, variables = list(log_terror = seq(quantile(wno_data$log_terror, .25, na.rm = T),
quantile(wno_data$log_terror, .75, na.rm = T),
by = .25),
log_hisppop = c(quantile(wno_data$log_hisppop, .25, na.rm = T),
quantile(wno_data$log_hisppop, .5, na.rm = T),
quantile(wno_data$log_hisppop, .75, na.rm = T))),
newdata = model.data2)) %>%
mutate(model_id = c(rep("model", 1296), rep("model2", (tally(.) - 1296))),
log_terror = (exp(log_terror)-1),
log_hisppop = exp(log_hisppop)) %>%
select(rowid, predicted, log_hisppop, log_terror, model_id) %>%
mutate(predicted = (exp(predicted)/(1 + exp(predicted)))) %>%
group_by(log_hisppop, log_terror, model_id) %>%
summarise(predicted_sum = mean(predicted))
View(temp)
quantile(wno_data$log_hisppop, .25, na.rm = T)
predictions(model, variables = list(log_terror = seq(quantile(wno_data$log_terror, .25, na.rm = T),
quantile(wno_data$log_terror, .75, na.rm = T),
by = .25),
log_hisppop = c(quantile(wno_data$log_hisppop, .25, na.rm = T),
quantile(wno_data$log_hisppop, .5, na.rm = T),
quantile(wno_data$log_hisppop, .75, na.rm = T))),
newdata = model.data)
log(424.8599)
fig4 <- predictions(model, variables = list(log_terror = seq(quantile(wno_data$log_terror, .25, na.rm = T),
quantile(wno_data$log_terror, .75, na.rm = T),
by = .25),
log_hisppop = c(quantile(wno_data$log_hisppop, .25, na.rm = T),
quantile(wno_data$log_hisppop, .5, na.rm = T),
quantile(wno_data$log_hisppop, .75, na.rm = T))),
newdata = model.data) %>%
rbind(.,
predictions(model2, variables = list(log_terror = seq(quantile(wno_data$log_terror, .25, na.rm = T),
quantile(wno_data$log_terror, .75, na.rm = T),
by = .25),
log_hisppop = c(quantile(wno_data$log_hisppop, .25, na.rm = T),
quantile(wno_data$log_hisppop, .5, na.rm = T),
quantile(wno_data$log_hisppop, .75, na.rm = T))),
newdata = model.data2)) %>%
mutate(model_id = c(rep("model", 1296), rep("model2", (tally(.) - 1296))),
log_terror = (exp(log_terror)-1),
log_hisppop = exp(log_hisppop)) %>%
select(rowid, predicted, log_hisppop, log_terror, model_id) %>%
mutate(predicted = (exp(predicted)/(1 + exp(predicted)))) %>%
group_by(log_hisppop, log_terror, model_id) %>%
summarise(predicted_sum = mean(predicted)) %>%
ggplot(aes(x = log_terror, y = predicted_sum, linetype = as.factor(log_hisppop))) +
geom_line() +
labs(y = '"Borders and Immigration" Grievance Probability',
x = "Number of Non-Right Wing Terror Threats or Attacks in U.S. in Previous Year") +
scale_linetype_discrete(#breaks = c(-1,0,1),
labels = c(expression("25"^{th}~"Percentile Hispanic Population in County"),
"Median Hispanic Population in County",
expression("75"^{th}~"Percentile Hispanic Population in County")),
name = "") +
theme_bw() +
theme(axis.title = element_text(face = "bold"),
legend.position = "top") +
facet_grid(~model_id,
labeller = labeller(model_id = labs))
ggsave("figures/fig4.jpeg", dpi = 600, height = 6, width = 12, units = "in")
fig4
dev.off()
quantile(wno_data$log_hisppop, .75, na.rm = T)
log(7831.4322)
wno_data2 <- wno_data[wno_data$year != 2002,] #Removing 2002 org-years
model2 <- plm(immigration ~ log_terror*log_hisppop + discursive_style +
per_repub + vcrime_rate + factor(reform) + p2001 + log_vocality +
word_count + factor(admin),
data = wno_data2,
index = c("org","year"),
model = "within") #the model with 2002 org-years removed
mat2 <- perm_tester(data = wno_data2, model = model2,
perm_var = "immigration", statistic = "coefficients",
strat_var = "org", seed = 123)
model2
mat2
nrow(model2$model)
model2$vcov
model2$assign
model2$contrasts
summary(model2)
model3 <- plm(immigration ~ log_terror*log_hisppop*p2001 + discursive_style +
per_repub + vcrime_rate + factor(reform) + log_vocality +
word_count + factor(admin),
data = wno_data,
index = c("org","year"),
model = "within")
mat3 <- perm_tester(data = wno_data, model = model3,
perm_var = "immigration", statistic = "coefficients",
strat_var = "org", seed = 123)
model3
mat3
summary(model3)
#Descriptive statistics
#For continuous variables
vars.con <- c("immigration","log_terror","log_hisppop",
"discursive_style","per_repub","vcrime_rate",
"log_vocality","word_count")
describe(model.data[vars.con])
apply(model.data[vars.con], 2, quantile, probs = .25)
apply(model.data[vars.con], 2, quantile, probs = .75)
model.1 <- plm(immigration ~ log_terror,
data = wno_data,
index = c("org","year"),
model = "within")
mat.1 <- perm_table(data = wno_data, model = model.1,
perm_v = "immigration", statistic = "coefficients",
strata_v = "org", seed = 123)
mat.1
wno_data[,c("org","year","hisp_new")] |> as.data.frame()
wno_data[,c("org","year","hisp_new.y")] |> as.data.frame()
model.2 <- plm(immigration ~ log_terror*log_hisppop,
data = wno_data,
index = c("org","year"),
model = "within")
mat.2 <- perm_tester(data = wno_data, model = model.2,
perm_var = "immigration", statistic = "coefficients",
strat_var = "org", seed = 123)
mat.2
mat
model
summary(model)
fit <- list(
feols(immigration ~ log_terror | org, data = wno_data),
feols(immigration ~ log_terror*log_hisppop | org, data = wno_data),
feols(immigration ~ log_terror*log_hisppop + discursive_style +
per_repub + vcrime_rate + factor(reform) + p2001 + log_vocality +
word_count + factor(admin) | org, data = wno_data)
)
lapply(fit, r2) #r2, adj r2, within-r2, adj within-r2
fit
lapply(fit, r2) #r2, adj r2, within-r2, adj within-r2
summary(model.1)
lapply(fit, function(x) sd(wno_data$immigration - x$fitted.values)) #rmse
mat.2
model.2
mat.2
mat
model
wno_data2 <- wno_data[wno_data$year != 2002,] #Removing 2002 org-years
model2 <- plm(immigration ~ log_terror*log_hisppop + discursive_style +
per_repub + vcrime_rate + factor(reform) + p2001 + log_vocality +
word_count + factor(admin),
data = wno_data2,
index = c("org","year"),
model = "within") #the model with 2002 org-years removed
mat2 <- perm_tester(data = wno_data2, model = model2,
perm_var = "immigration", statistic = "coefficients",
strat_var = "org", seed = 123)
model2
mat2
model3 <- plm(immigration ~ log_terror*log_hisppop*p2001 + discursive_style +
per_repub + vcrime_rate + factor(reform) + log_vocality +
word_count + factor(admin),
data = wno_data,
index = c("org","year"),
model = "within")
mat3 <- perm_tester(data = wno_data, model = model3,
perm_var = "immigration", statistic = "coefficients",
strat_var = "org", seed = 123)
model3
mat3
fit.2 <- list(
feols(immigration ~ log_terror*log_hisppop + discursive_style +
per_repub + vcrime_rate + factor(reform) + p2001 + log_vocality +
word_count + factor(admin) | org, data = wno_data2),
feols(immigration ~ log_terror*log_hisppop*p2001 + discursive_style +
per_repub + vcrime_rate + factor(reform) + log_vocality +
word_count + factor(admin) | org, data = wno_data)
)
lapply(fit.2, r2)
colnames(wno_data)
wno_data$hisp_inter <- NA
wno_data$hisp_interprop <- NA
wno_data$construal <- NA
wno_data$construal_rolling <- NA
wno_data$immigration_rolling <- NA
wno_data$construal_style <- NA
wno_data$hisp_pop <- NA
wno_data$id <- NA
wno_data$hisp_new.x <- NA
wno_data$hisp_count <- wno_data$hisp_prop.y
wno_data$hisp_prop.y <- NA
wno_data$hisp_count <- wno_data$hisp_new.y
wno_data$hisp_new.y <- NA
colnames(wno_data)
wno_data <- wno_data[,c("org","year","terror_nright","population","vcrime","vocality","admin","reform","per_repub","p2001","1","2","3","4","5","6","7","8","word_count","discursive_style","log_terror","log_hisppop","vcrime_rate","log_vocality","hisp_count")]
saveRDS(wno_data, "data/wno_data.rds")
pacman::p_load(tidyverse,
tidytext,
quanteda,
tm,
readtext,
textreg,
textclean,
textstem,
stringi,
udpipe,
text2map,
stm,
Hmisc,
install = T)
data <- readtext(paste0(getwd(), "/TXTs/*"))
# Not sure why doc_id sometimes gets duplicated, but below fixes it if it happens
# data$doc_id <- gsub(".*/", "", data$doc_id)
# data <- unique(data)
pre.meta <- readRDS("data/meta.rds")
#pre STM cleaning
data <- data %>%
#transliterate
mutate(text = stri_trans_general(text,
id = "Any-Latin;Latin-ASCII"),
#lowercase
text = tolower(text),
#replace curly quotes
text = replace_curly_quote(text),
#remove punctuation external to a word group
text = gsub("(\\w+[_'-]+\\w+)|[[:punct:]]+", "\\1", text),
#replace contractions
text = replace_contraction(text),
#remove numbers
text = gsub("[[:digit:]]+", " ", text),
#remove excess whitespace between words
text = gsub("[[:space:]]+", " ", text),
#remove excess whitespace at begining and end of strings
text = trimws(text))
data$doc_id <- gsub(".*/", "", data$doc_id)
data <- unique(data)
#pre STM cleaning
data <- data %>%
#transliterate
mutate(text = stri_trans_general(text,
id = "Any-Latin;Latin-ASCII"),
#lowercase
text = tolower(text),
#replace curly quotes
text = replace_curly_quote(text),
#remove punctuation external to a word group
text = gsub("(\\w+[_'-]+\\w+)|[[:punct:]]+", "\\1", text),
#replace contractions
text = replace_contraction(text),
#remove numbers
text = gsub("[[:digit:]]+", " ", text),
#remove excess whitespace between words
text = gsub("[[:space:]]+", " ", text),
#remove excess whitespace at begining and end of strings
text = trimws(text))
pre.meta <- pre.meta[order(match(rownames(pre.meta), data$doc_id)),]
identical(rownames(pre.meta), data$doc_id) #should be true
pre.meta$doc_id <- paste0("doc", 1:nrow(data))
eng <- udpipe_download_model(language = "english-gum")
ud_eng <- udpipe_load_model(eng$file_model)
lemmas <- udpipe_annotate( #this can take a while; you can instead load
#the lemmas.rds file in the repo
x = data$text,
object = ud_eng) %>%
as_tibble() %>%
select(doc_id, lemma) %>%
group_by(doc_id, lemma) %>%
dplyr::summarize(n = n())
# Get triplet matrix
df <- lemmas %>% #This can take a long time
#remove words that are 2 characters long or less
filter(!nchar(lemma) <= 2) %>%
#remove English stop words in the Onix, SMART, or Snowball stop lists
anti_join(stop_words, by = c("lemma" = "word")) %>%
filter(!(lemma %in% c("page")))
# get DTM
dtm <- df %>%
cast_dtm(
document = doc_id,
term = lemma,
value = n,
weighting = tm::weightTf
)
# remove sparse terms
dtm <- removeSparseTerms(dtm, 0.6)
dtm
#Prep for STM
pre.meta <- pre.meta[order(match(pre.meta$doc_id, rownames(dtm))),]
identical(pre.meta$doc_id, rownames(dtm)) #should be TRUE
out <- readCorpus(dtm, type = "slam")
out <- prepDocuments(out$documents, out$vocab, pre.meta)
docs <- out$documents
vocab <- out$vocab
meta <- out$meta
identical(names(docs), meta$doc_id) #should be TRUE
# Find optimal k
wn_modelk <- searchK(docs, vocab, K = seq(2, 20, by = 1), N = 50,
heldout.seed = 0.5, init.type = "Spectral",
prevalence =~ s(year) + ideo,
data = meta)
ggplot(data = wn_modelk$results, aes(x = as.numeric(semcoh), y = as.numeric(exclus))) +
geom_text(aes(label = K)) +
xlab("Semantic Coherence") +
ylab("Exclusivity") +
theme_bw() +
theme(axis.title = element_text(face = "bold"),
panel.grid = element_blank())
# Get model
wn.stm <- stm(docs, vocab, K = 8,
prevalence =~ s(year) + ideo,
data = meta,
init.type = "Spectral")
# Interpret the topics
colMeans(wn.stm$theta) #marginal topic probabilities
sageLabels(wn.stm, 10) #Topic #2 = Borders and Immigration
pre.meta <- pre.meta[,c("org","year","state","ideo")]
View(pre.meta)
saveRDS(pre.meta, "data/meta.rds")
